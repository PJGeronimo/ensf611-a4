{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92778525",
   "metadata": {},
   "source": [
    "# Assignment 4: Pipelines and Hyperparameter Tuning (32 total marks)\n",
    "### Due: November 22 at 11:59pm\n",
    "\n",
    "### Name: Paolo Geronimo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce31b39a",
   "metadata": {},
   "source": [
    "### In this assignment, you will be putting together everything you have learned so far. You will need to find your own dataset, do all the appropriate preprocessing, test different supervised learning models and evaluate the results. More details for each step can be found below.\n",
    "\n",
    "### You will also be asked to describe the process by which you came up with the code. More details can be found below. Please cite any websites or AI tools that you used to help you with this assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf275ca7",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2b67a661",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8219f163",
   "metadata": {},
   "source": [
    "## Step 1: Data Input (4 marks)\n",
    "\n",
    "Import the dataset you will be using. You can download the dataset onto your computer and read it in using pandas, or download it directly from the website. Answer the questions below about the dataset you selected. \n",
    "\n",
    "To find a dataset, you can use the resources listed in the notes. The dataset can be numerical, categorical, text-based or mixed. If you want help finding a particular dataset related to your interests, please email the instructor.\n",
    "\n",
    "**You cannot use a dataset that was used for a previous assignment or in class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "2af8bd32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dataset (1 mark)\n",
    "\n",
    "# The dataset I chose is the \"Computer Hardware\" dataset from the UCI ML Repo.\n",
    "# The dataset's taget variable is CPU Estimated Relative Performance (ERP),\n",
    "# and the feature set is a particular CPU's specifications.\n",
    "# Link to dataset is found below in the answer to question 1.\n",
    "\n",
    "#using the column names found in machine.names\n",
    "column_names = ['Vendor', 'Model', 'MYCT', 'MMIN', 'MMAX', 'CACH', 'CHMIN', 'CHMAX', 'PRP', 'ERP']\n",
    "X = pd.read_csv('machine.data', names = column_names)\n",
    "\n",
    "# creating feature matrix and target vector\n",
    "y = X['ERP']\n",
    "X.drop('ERP', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20316765",
   "metadata": {},
   "source": [
    "### Questions (3 marks)\n",
    "\n",
    "1. (1 mark) What is the source of your dataset?\n",
    "1. (1 mark) Why did you pick this particular dataset?\n",
    "1. (1 mark) Was there anything challenging about finding a dataset that you wanted to use?\n",
    "\n",
    "*ANSWER HERE*\n",
    "1. My dataset is sourced from the UCI Machine Learning repository: https://archive.ics.uci.edu/dataset/29/computer+hardware\n",
    "2. I picked this dataset because one of my hobbies is building PCs, so an analysis on this dataset would be interesting to me.\n",
    "3. There wasn't anything challenging in particular about finding a dataset. I looked at previous assignments to see where those datasets were from, so I checked the source to see if there were any other interesting datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42fea4cc",
   "metadata": {},
   "source": [
    "## Step 2: Data Processing (5 marks)\n",
    "\n",
    "The next step is to process your data. Implement the following steps as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "afc244d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X: (209, 9)\n",
      "Type of X:\n",
      "Vendor    object\n",
      "Model     object\n",
      "MYCT       int64\n",
      "MMIN       int64\n",
      "MMAX       int64\n",
      "CACH       int64\n",
      "CHMIN      int64\n",
      "CHMAX      int64\n",
      "PRP        int64\n",
      "dtype: object\n",
      "Shape of y: (209,)\n",
      "Type of y:\n",
      "int64\n"
     ]
    }
   ],
   "source": [
    "# Clean data (if needed)\n",
    "print (f\"Shape of X: {X.shape}\")\n",
    "print (\"Type of X:\")\n",
    "print (X.dtypes)\n",
    "\n",
    "print (f\"Shape of y: {y.shape}\")\n",
    "print (\"Type of y:\")\n",
    "print (y.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "032a181c-8eb8-4751-ace0-42c09b7d6865",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vendor    0\n",
      "Model     0\n",
      "MYCT      0\n",
      "MMIN      0\n",
      "MMAX      0\n",
      "CACH      0\n",
      "CHMIN     0\n",
      "CHMAX     0\n",
      "PRP       0\n",
      "dtype: int64\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# check nulls\n",
    "print(X.isnull().sum())\n",
    "print(y.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "40d413c6-5064-4220-84b1-dddc25b53117",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "209\n"
     ]
    }
   ],
   "source": [
    "# Since there are potentially lots of unique model names, let's take a look and see if we should drop the column\n",
    "print(X['Model'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "24c496bf-d359-4928-83f5-5f1092aee2f8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(209, 8)\n"
     ]
    }
   ],
   "source": [
    "# There are 209 unique model names, which makes sense since there are 209 samples in the dataset.\n",
    "# Using this as a categorical feature wouldn't make much sense so I'll drop it.\n",
    "\n",
    "X.drop('Model', axis = 1, inplace = True)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "70a8c127",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement preprocessing steps. Remember to use ColumnTransformer if more than one preprocessing method is needed\n",
    "\n",
    "# I'll choose to use the Lasso, SVR, and KNeighborsRegressor models, so I will scale my data using a StandardScaler.\n",
    "# The Vendor feature is categorical, so I will use One Hot Encoding.\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "ct = ColumnTransformer(\n",
    "    [('onehot', OneHotEncoder(sparse_output = False), ['Vendor']),\n",
    "      ('scaling', StandardScaler(), ['MYCT', 'MMIN', 'MMAX', 'CACH', 'CHMIN', 'CHMAX', 'PRP'])])\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 0) \n",
    "ct.fit(X_train)\n",
    "X_train_trans = ct.transform(X_train)\n",
    "X_test_trans = ct.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b92c46b7",
   "metadata": {},
   "source": [
    "### Questions (2 marks)\n",
    "\n",
    "1. (1 mark) Were there any missing/null values in your dataset? If yes, how did you replace them and why? If no, describe how you would've replaced them and why.\n",
    "2. (1 mark) What type of data do you have? What preprocessing methods would you have to apply based on your data types?\n",
    "\n",
    "*ANSWER HERE*\n",
    "1. There were no missing values in my dataset. If there were, I would probably replace them with the mean of that column from that particular vendor, as opposed to the entire mean.\n",
    "\n",
    "2. My data types were 1 string feature, and 7 integers. Based on this, I used one hot encoding on the string, and standard scaling on the integers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a245d00",
   "metadata": {},
   "source": [
    "## Step 3: Implement Machine Learning Model (11 marks)\n",
    "\n",
    "In this section, you will implement three different supervised learning models (one linear and two non-linear) of your choice. You will use a pipeline to help you decide which model and hyperparameters work best. It is up to you to select what models to use and what hyperparameters to test. You can use the class examples for guidance. You must print out the best model parameters and results after the grid search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5558a776",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement pipeline and grid search here. Can add more code blocks if necessary\n",
    "# I will use the Lasso, SVR, and KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dbd7075",
   "metadata": {},
   "source": [
    "### Questions (5 marks)\n",
    "\n",
    "1. (1 mark) Do you need regression or classification models for your dataset?\n",
    "1. (2 marks) Which models did you select for testing and why?\n",
    "1. (2 marks) Which model worked the best? Does this make sense based on the theory discussed in the course and the context of your dataset?\n",
    "\n",
    "*ANSWER HERE*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f994e31",
   "metadata": {},
   "source": [
    "## Step 4: Validate Model (6 marks)\n",
    "\n",
    "Use the testing set to calculate the testing accuracy for the best model determined in Step 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e64c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate testing accuracy (1 mark)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e4529ba",
   "metadata": {},
   "source": [
    "\n",
    "### Questions (5 marks)\n",
    "\n",
    "1. (1 mark) Which accuracy metric did you choose? \n",
    "1. (1 mark) How do these results compare to those in part 3? Did this model generalize well?\n",
    "1. (3 marks) Based on your results and the context of your dataset, did the best model perform \"well enough\" to be used out in the real-world? Why or why not? Do you have any suggestions for how you could improve this analysis?\n",
    "\n",
    "*ANSWER HERE*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b238f4",
   "metadata": {},
   "source": [
    "## Process Description (4 marks)\n",
    "Please describe the process you used to create your code. Cite any websites or generative AI tools used. You can use the following questions as guidance:\n",
    "1. Where did you source your code?\n",
    "1. In what order did you complete the steps?\n",
    "1. If you used generative AI, what prompts did you use? Did you need to modify the code at all? Why or why not?\n",
    "1. Did you have any challenges? If yes, what were they? If not, what helped you to be successful?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93097bfe",
   "metadata": {},
   "source": [
    "*DESCRIBE YOUR PROCESS HERE*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd97b6ac",
   "metadata": {},
   "source": [
    "## Reflection (2 marks)\n",
    "Include a sentence or two about:\n",
    "- what you liked or disliked,\n",
    "- found interesting, confusing, challenging, motivating\n",
    "while working on this assignment.\n",
    "\n",
    "\n",
    "*ADD YOUR THOUGHTS HERE*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241c3b12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
